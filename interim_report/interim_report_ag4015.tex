\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx} %package to manage images
\graphicspath{ {Images/} }
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\usepackage{listings}
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage[margin=1.5in]{geometry}

\usepackage{amsmath}
\usepackage{mathpazo} % Palatino font
% \usepackage[style=authoryear,backend=biber]{biblatex}
\lstset{frame=tb,
  language=Matlab,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage[
    backend=biber,
    style=numeric,
		sorting=none,
    natbib=true,
    url=false,
    doi=true,
    eprint=false
]{biblatex}
\addbibresource{references.bib}
\begin{document}


\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here
	
	\center % Centre everything on the page
	
	%------------------------------------------------
	%	Headings
	%------------------------------------------------
	
	\textsc{\LARGE Imperial College London}\\[1.5cm] % Main heading such as the name of your university/college
	
	\textsc{\Large Electrical and Electronic Engineering Department}\\[0.5cm] % Major heading such as course name
	
	%------------------------------------------------
	%	Title
	%------------------------------------------------
	
	\HRule\\[0.4cm]
	
	{\huge\bfseries Interim Report}\\[0.4cm] % Title of your document
	
	\HRule\\[1.5cm]
	
	%------------------------------------------------
	%	Author(s)
	%------------------------------------------------
	
	
	% If you don't want a supervisor, uncomment the two lines below and comment the code above
	{\large\textit{Project title}}\\
	\textsc{Structure and dynamics of large networks of interacting neurons}
	
	\vfill
	%------------------------------------------------
	%	Author(s)
	%------------------------------------------------
	
	
	% If you don't want a supervisor, uncomment the two lines below and comment the code above
	{\large\textit{Author}}\\
	\textsc{Alejandro Gilson Campillo} \quad \text{CID: 01112712} % Your name
	
	\vfill
	%------------------------------------------------
	%	Supervisor
	%------------------------------------------------
	
	
	{\large\textit{Supervisor}}\\
	\textsc{Prof. Pier Luigi Dragotti} 
	%------------------------------------------------
	%	Second Marker
	%------------------------------------------------
	
	\vfill
	
	{\large\textit{Second Marker}}\\
	\textsc{Dr. Wei Dai} 
	%------------------------------------------------
	%	Date
	%------------------------------------------------
	\vfill\vfill\vfill % Position the date 3/4 down the remaining page
	
	{\large\today} % Date, change the \today to a set date if you want to be precise
	
	%------------------------------------------------
	%	Logo
	%------------------------------------------------
	
	\vfill\vfill
	 
	\includegraphics[width=5cm]{imperialcollegelondon.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package	
	%----------------------------------------------------------------------------------------
	
	\vfill % Push the date up 1/4 of the remaining page
	
\end{titlepage}


\section{Introduction}

The brain is a complex machine, it allows the human being to think, communicate and feel. It does so thanks to the billions of neurons that communicate in a dense network through synapses. However, little is known about how it works. By studying how the neurons structure to to store and process information we can understand how the brain as a whole functions. This could have important applications in medicine for curing diseases such as Parkinson \cite{OldeDubbelinkKimT.E.2014Dbnt} and epilepsy \cite{PONTEN2007918}, and in machine learning for the development of more intelligent neural networks.
\\\\
In order to infer the network structure of a set of neurons, they are treated as a diffusion network where electrical spikes increase the likelihood of connected neurons to spike and therefore transmit a signal that travels as if it were a disease. By evaluating the time of "infection", the relationship between two neurons can be probabilistically estimated. After computing the relationship between all of the neurons, an estimate of the topology of the network can be obtained. 
\\\\
Previous work on this topic \cite{pranav_report, alexandru2018estimating} evaluated the feasibility of using a maximum-likelihood estimator algorithm, NetRate \cite{rodriguez2011uncovering}, for the structure inference of biological neural networks. A network was simulated using the Izhikevic neuron model \cite{izhikevich2003simple} and the brian simulator \cite{10.3389/neuro.01.026.2009}. The connections between the neurons were then estimated, compared to the original network and the performance of the algorithm was evaluated.
\\
\\
The aim of this project is to improve on the state of the art research of network inference and the understanding of the underlying structure of the brain. There are many ways in which this can be done such as scalability and the addition of different types of neurons to the model.It would also be useful to test the accuracy of the algorithm on real interacting neurons. Developments in technology allow us to obtain spike data from individual neurons \cite{ito2016spontaneous, ito2014large, litke2004does}.


\section{Background}

\subsection{Definition of connectivity}

The definition of connectivity between neurons has a history of lack of consensus among the scientific community \cite{HORWITZ2003466}. Connectivity studies from different researchers may lead to different results depending on how they define it, as they may be looking at different aspects of connectivity. The two main accepted definitions that are used are functional and effective connectivity.
\\
Functional connectivity is the temporal correlation between spatially remote neurophysiological events \cite{friston1993functional}. Studies on this topic began with electroencephalography (EEG) measurements. Some methods to measure functional connectivity include the evaluation of the correlation in the frequency domain between EEG signals at different scalp locations \cite{pfurtscheller1999event}, and the cross-correlation of the time series measurements from a pair of electrodes \cite{gevins1985neurocognitive}. However, due to the volume conduction of brain tissue, the electrical activity from the scalp cannot infer the individual neuron behaviour below the electrode \cite{HORWITZ2003466}.
\\
Effective connectivity was defined in \cite{friston1993functional} as the influence that one neural system exerts on another. Effective connectivity can be measured in terms of efficacy and contribution. At a synaptic level it can be expressed as in Eq.\ref{eq:synaptic_effectivity}, where $x_{j}$ is the post-synaptic response to many pre-synaptic inputs $x_{i}$ and $\textbf{W}_{ij}$ is the efficacy of the connections between neurons $i$ and $j$. Contribution is reflected in Eq.\ref{eq:synaptic_contribution} as the effect of $i$ on $j$ relative to all pre-synaptic inputs. Using this definition, directional effects are taken into account and a richer representation of the network can be attained. Following the approach in \cite{alexandru2018estimating}, this project will focus on the effective connectivity of neurons in a network.
\\

\begin{equation}\label{eq:synaptic_effectivity}
x_{j} = \Sigma \textbf{W}_{ij}\times x_{i}
\end{equation}

\begin{equation}\label{eq:synaptic_contribution}
\frac{\textbf{W}_{ij}}{\Sigma \textbf{W}_{ij}}
\end{equation}

\subsection{Izhikevich neuron model}

In order to understand how the brain works we must be able to replicate the behaviour of individual neurons applying simple and accurate models. However, meeting both criteria can be challenging. The Hodgkinâ€“Huxley model \cite{hodgkin1952quantitative} is very accurate as it can emulate the rich firing patterns of many types of neurons. However, it is very computationally expensive and only a few neurons can be computed in real time. The integrate-and-fire model \cite{burkitt2006review}  has the opposite problem: it is computationally simple but it is an unrealistic representation of the neuron since it does not capture the firing patterns with sufficient accuracy \cite{izhikevich2003simple}.
\\
In contrast, the Izhikevich neuron model \cite{izhikevich2003simple} meets both criteria. Tens of thousands of spiking cortical neurons can be simulated in real time by simplifying the Hodgkin-Huxley model into the two dimensional system of differential equations shown below.


\begin{align}\label{eq:izhikevich_ode}
&v'=0.04v^{2}+5v+140-u+\textbf{I} \\
&u'=a(bv-u)
\end{align}

with the auxiliary after-spike reseting

\begin{equation}\label{eq:izhikevich_reset}
\text{if } v \geq 30 \text{mV, then}
\begin{cases}
    v     & \leftarrow c \\
    u     & \leftarrow u + d 
  \end{cases}
\end{equation}

Here, the dimensionless variables $v$ and $u$ represent the membrane potential of the neuron and the membrane recovery, respectively. When a spike reaches its apex (30 mV), both these variables are reset according to Eq. \ref{eq:izhikevich_reset}. Synaptic or injected DC currents are represented by the variable \textbf{I}. The threshold is not fixed, just as with real neurons and it's based on previous spikes. 
\\
On the other hand, $a, b, c$ and $d$ are dimensionless parameters. $a$ determines the speed of the recovery variable $u$, $b$ defines the sensitivity of the recovery variable $u$ to sub-threshold fluctuations of the membrane potential $v$. Finally, $c$ and $d$ determine the after-spike reset value of the recovery variables $v$ and $u$, respectively. 
\\
The relevance of this algorithm stems from the fact that, different combinations of the parameters provide the model with a rich variety of firing patterns. When analysing the neocortical neurons in the mammalian brain, a number of different classes of excitatory neurons can be found \cite{connors1990intrinsic, gray1996chattering} such as RS (regular spiking), IB (intrinsically bursting) and CH (chattering). From the inhibitory type of neurons, two classes can be found: FS (fast spiking and LTS (low-threshold spiking). Other interesting classes of neurons are the TC (thalamo-cortical) and the RZ (resonator). It is of great importance to understand what types of neurons can be found so that a simulated network can become a closer representation of what can be found on a real brain. In order to simplify the network to be inferred, the only type of neurons simulated in the network were the regular spiking neurons. This was achieved by setting the parameters to $a=0.02$, $b=0.2$, $c=-65$ and $d=8$. This type of neuron is the most common type of excitatory neuron in the brain. There is also a ratio of excitatory and inhibitory neurons of 4 to 1 in the mammalian brain, respectively \cite{izhikevich2003simple}.


\subsection{Netrate}

\subsubsection{Diffusion processes}

In order to infer the underlying structure of a network, \cite{alexandru2018estimating} employed  NetRate algorithm developed by Rodriguez \cite{rodriguez2011uncovering} by treating the network as a diffusion process.

The study of diffusion network is based on the observation of the nodes in a system when they take a certain action: get infected by a virus, share a piece of information, etc. A problem concerning this kind of studies lies on the fact that we can only understand when and where these nodes propagate but not how or why the do so. An example of this is the propagation of a virus in a population. We can tell who and when somebody got infected but not who infected him. For the rest of this section we will refer to the propagation of an infection as the object of study of the network. 

To infer the mechanisms behind diffusion processes the time of infection is analysed. A model needs to be created with some assumptions about the structures that generate diffusion processes:

\begin{itemize}
\item The network in a diffusion process is fixed, unknown and directed.
\item Infections are binary, they can only be infected or not infected, no partial infections are considered.
\item Infections across the edges of the network occur independently from one another.
\item The likelihood of a node $a$ infecting node $b$ at time $t$ is modelled by a probability distribution dependent on $a, b$ and $t$.
\item All infections in a network are observed during a recorded time window.
\end{itemize}

NetRate aims to describe how infections occur during a period of time in a fixed network. This is achieved by finding the optimal network and transmission rates that maximizes the likelihood of a set of observed cascades to occur. The mathematical definitions that construct this model will be explained in the following section.


\subsubsection{Mathematical definitions}

The following definitions in this section are necessary for the construction of the model with which we intend to infer the connectivity of the network. First, the data that is going to be analysed will be defined:

\begin{itemize}
\item Observations are carried out on a population of $N$ nodes that have created a set of $C$ cascades $\{\textbf{t}^{1},\cdots,\textbf{t}^{|C|}\}$. 
\item Each of the cascades $\textbf{t}^{c}$ contains the infection times of all the population within a time period $T^{c}$.
\item Each of the cascades is an N-dimensional vector with recordings of when the nodes were infected in the cascade. If a node was not infected during the time period $[0,T^{c}]$, a symbol $\infty$ is assigned. This does not mean that the node never gets infected.
\begin{equation}\label{eq:data_netrate}
\textbf{t}^{c}:=(t_{1}^{c},\cdots,t_{N}^{c}),\quad t_{k}^{c}\in [0,T^{c}]\cup{\infty}
\end{equation}
\item For simplicity, $T^{c}=T$
\item Node $i$ is parent of node $j$ if $t_{i}<t_{j}$ within the cascade.
\end{itemize}

The pairwise interactions are to be studied in order to obtain the pairwise transmission likelihood between nodes in the network. It will be assumed that infections can occur at different rates along different edges in the network. 

\begin{itemize}
\item $f(t_{i}|t_{j},\alpha _{j,i})$ is the conditional likelihood of transmission between nodes $j$ and $i$. It depends on the infection times $(t_{i},t{j})$ and pairwise transmission rate $\alpha_{j,i}$.
\item A node cannot be infected by a healthy node. Node $j$, infected at $t_{j}$, can only infect node $i$ at time $t_{i}$ if and only if $t_{j}<t_{i}$.
\item Transmission rate $\alpha _{j,i}\geq0$.
\end{itemize}

The cumulative density function is defined as $F(t_{i}|t_{j};\alpha _{j,i})$ and is obtained from the transmission likelihood. If a node $j$ was infected at time $t_{j}$, the probability that node $i$ is not infected by node $j$ by time $t_{i}$ is given by the survival function of the edge $j\rightarrow i$:

\begin{equation}\label{eq:survival_function}
S(t_{i}|t_{j};\alpha _{j,i})=1-F(t_{i}|t_{j};\alpha _{j,i})
\end{equation}

The instantaneous infection rate, or hazard function, of the edge $j\rightarrow i$ is the ratio of the transmission likelihood over the survival function as shown in Eq.\ref{eq:hazard_function}.

\begin{equation}\label{eq:hazard_function}
H(t_{i}|t_{j};\alpha _{j,i})=\frac{f(t_{i}|t_{j};\alpha _{j,i})}{S(t_{i}|t_{j};\alpha _{j,i})}
\end{equation}

With a complete set of definitions, it will now be possible to derive the algorithm behind NetRate as it will be shown in the next section.

\subsubsection{Derivation of NetRate}

Rodriguez \cite{rodriguez2011uncovering} derives NetRate by studying the individual probability of infection of the nodes and then building the whole of the network. The probability of survival of any cascade is the probability that a node is not infected until time $T$, given that the parents are infected at the beginning of the cascade. For a non-infected node $i$, the probability that any of the nodes $1\cdots N$ does not infect node $i$ by time $T$ is given by the product of the survival functions of each of the infected nodes $k$ targeting node $i$ because the different probabilities of infection are considered independent. This is illustrated in Eq.\ref{eq:step_1_netrate}.

\begin{equation}\label{eq:step_1_netrate}
\prod_{t_{k}\leq T}S(T\mid t_{k};\alpha _{k,i})
\end{equation}

To compute the likelihood of a cascade $\textbf{t}:=(t_{1},\cdots,t_{N}|t_{i}\leq T)$ we require the the likelihood of the recorded infections $\textbf{t}^{\leq T}=(t_{1},\cdots,t_{N}|t_{i}\leq T)$. Again, using independence, the likelihood factorizes as seen in \ref{eq:step_2_netrate}. The likelihood of the cascade then becomes the conditional likelihood of the infection time given the rest of the cascade.

\begin{equation}\label{eq:step_2_netrate}
f(\textbf{t}^{\leq T};\textbf{A})=\prod_{t_{i}\leq T}f(t_{i}\mid t_{1},\cdots,t_{N}\textbackslash t_{i};\textbf{A})
\end{equation}

As in \cite{kempe2003maximizing}, a node gets infected when the first parent infects the node. We now compute the likelihood of a potential parent $j$ of being the first one by using Eq.\ref{eq:step_1_netrate}.

\begin{equation}\label{eq:step_3_netrate}
f(t_{i}\mid t_{j};\alpha_{j,i})\times \prod_{j\neq k,t_{k}< t_{i}}S(t_{i}\mid t_{k};\alpha _{k,i})
\end{equation}
 
In this step, we calculate the conditional likelihood of Eq.\ref{eq:step_2_netrate} by adding all the likelihoods of the mutually disjoint likelihoods that each potential parent is the first parent:

\begin{equation}\label{eq:step_4_netrate}
f(t_{i}\mid t_{1},\cdots,t_{N}\textbackslash t_{i};\textbf{A})=\sum_{j:t_{j}<t_{i}}f(t_{i}\mid t_{j};\alpha _{j,i})\times \prod _{j\neq k,t_{k}<t_{i}}S(t_{i}\mid t_{k};\alpha _{k,i})
\end{equation}

Using Eq.\ref{eq:step_2_netrate} and removing the condition $k\neq j$, the likelihood of infections then becomes:

\begin{equation}\label{eq:step_5_netrate}
f(\textbf{t}^{\leq T};\textbf{A})=\prod_{t_{i}\leq T}\prod_{k:t_{k}<t_{i}}S(t_{i}\mid t_{k};\alpha _{k,i})\times \sum_{j:t_{j}<t_{i}}\frac{f(t_{i}\mid t_{j};\alpha_{j,i})}{S(t_{i}\mid t_{j};\alpha _{j,i})}
\end{equation}

However, Eq.\ref{eq:step_5_netrate} needs to consider also the nodes that are not infected during the observation window. For this reason we add the multiplicative survival term from Eq.\ref{eq:step_1_netrate} and replace the ratios from Eq.\ref{eq:step_5_netrate} with hazard functions:

\begin{equation}\label{eq:step_6_netrate}
f(\textbf{t};\textbf{A})=\prod_{t_{i}\leq T}\prod_{t_{m}>T}S(T\mid t_{i};\alpha_{i,m})\times \prod_{k:t_{k}<t_{i}}S(t_{i}\mid t_{k};\alpha _{k,i})\sum_{j:t_{j}<t_{i}}H(t_{i}\mid t_{j};\alpha _{j,i})
\end{equation}

The likelihood of a set of independent set of cascades $C=\{t^{1},\cdots,t^{|C|}\}$ is the product of the likelihoods of all the individual cascades given by Eq.\ref{eq:step_6_netrate}:

\begin{equation}\label{eq:step_7_netrate}
\prod _{\textbf{t}^{c}\in C}f(\textbf{t}^{c};\textbf{A})
\end{equation}

\printbibliography 


\end{document}











